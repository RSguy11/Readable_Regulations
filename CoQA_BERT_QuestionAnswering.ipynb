{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering with a fine-tuned BERT on CoQA dataset\n",
    "\n",
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3urfvvm165iantk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version                                               data\n",
       "0        1  {'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...\n",
       "1        1  {'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...\n",
       "2        1  {'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...\n",
       "3        1  {'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...\n",
       "4        1  {'source': 'gutenberg', 'id': '3urfvvm165iantk..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coqa = pd.read_json('http://downloads.cs.stanford.edu/nlp/data/coqa/coqa-train-v1.0.json')\n",
    "coqa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del coqa[\"version\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = [\"text\",\"question\",\"answer\"]\n",
    "\n",
    "# j = 1\n",
    "comp_list = []\n",
    "for index, row in coqa.iterrows():\n",
    "    for i in range(len(row[\"data\"][\"questions\"])):\n",
    "        temp_list = []\n",
    "#         temp_list.append(j)\n",
    "        temp_list.append(row[\"data\"][\"story\"])\n",
    "        temp_list.append(row[\"data\"][\"questions\"][i][\"input_text\"])\n",
    "        temp_list.append(row[\"data\"][\"answers\"][i][\"input_text\"])\n",
    "        comp_list.append(temp_list)\n",
    "#     j += 1\n",
    "new_df = pd.DataFrame(comp_list, columns=cols) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the data as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"CoQA_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>When was the Vat formally opened?</td>\n",
       "      <td>It was formally established in 1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what is the library for?</td>\n",
       "      <td>research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>for what subjects?</td>\n",
       "      <td>history, and law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>and?</td>\n",
       "      <td>philosophy, science and theology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what was started in 2014?</td>\n",
       "      <td>a  project</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Vatican Apostolic Library (), more commonl...   \n",
       "1  The Vatican Apostolic Library (), more commonl...   \n",
       "2  The Vatican Apostolic Library (), more commonl...   \n",
       "3  The Vatican Apostolic Library (), more commonl...   \n",
       "4  The Vatican Apostolic Library (), more commonl...   \n",
       "\n",
       "                            question                               answer  \n",
       "0  When was the Vat formally opened?  It was formally established in 1475  \n",
       "1           what is the library for?                             research  \n",
       "2                 for what subjects?                     history, and law  \n",
       "3                               and?     philosophy, science and theology  \n",
       "4          what was started in 2014?                           a  project  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"CoQA_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question and answers:  108647\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of question and answers: \", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e2bfea3a1349dba02ae6ff6fc06953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naesl\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\naesl\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45573458a1146cdb54d3e1a93cd84b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d89f259aac4c4282dbe8dd859904d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d831a677f244d1eb8dfd106b1cbd4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f618b04fb02e46ebb60f206fdb7d1ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num = np.random.randint(0,len(data))\n",
    "\n",
    "question = data[\"question\"][random_num]\n",
    "text = data[\"text\"][random_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When did that happen? \n",
      " Moscow (CNN)More than 1 million historic documents have been destroyed in a fire at one of Russia's largest public libraries, according to the Russian state news agency Tass. \n",
      "\n",
      "The Russian emergency situations ministry says 147 firefighters struggled for 25 hours over the weekend to put out the blaze in the main library of the Institute for Research Information on Social Sciences in Moscow. \n",
      "\n",
      "The fire, which ripped through the library Friday evening, destroyed 2,000 square meters (about 2,400 square yards) of the building and caused part of the roof to collapse, according to an official statement. The Russian emergency situations ministry said the fire was particularly hard to put out because of the high temperatures, narrow passageways and the risk of the building falling down. \n",
      "\n",
      "Moscow's emergency ministry said the temperature inside the rubble of the library remains high and that there is still a threat that the building could collapse. \n",
      "\n",
      "Vladimir Fortov, president of the Russian Academy of Sciences, told the Russian news agency RIA Novosti that the fire, which destroyed 15% of all the documents in the library, reminded him of the 1986 disaster at the Chernobyl nuclear plant in Ukraine. \n",
      "\n",
      "\"It's a major loss for science. This is the largest collection of its kind in the world, probably equivalent to the Library of Congress,\" Fortov told the agency. \"It contains material that you can't find anywhere else and all the social science institutions use this library. What has happened here is reminiscent of Chernobyl.\" \n",
      "\n",
      "The institute's director, Yuri Pivovarov, told Tass that he fears the building cannot be restored. \n"
     ]
    }
   ],
   "source": [
    "print(question, \"\\n\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input has a total of 332 tokens.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(question, text)\n",
    "print(\"The input has a total of {} tokens.\".format(len(input_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]        101\n",
      "when       2,043\n",
      "did        2,106\n",
      "that       2,008\n",
      "happen     4,148\n",
      "?          1,029\n",
      "[SEP]        102\n",
      "moscow     4,924\n",
      "(          1,006\n",
      "cnn       13,229\n",
      ")          1,007\n",
      "more       2,062\n",
      "than       2,084\n",
      "1          1,015\n",
      "million    2,454\n",
      "historic   3,181\n",
      "documents   5,491\n",
      "have       2,031\n",
      "been       2,042\n",
      "destroyed   3,908\n",
      "in         1,999\n",
      "a          1,037\n",
      "fire       2,543\n",
      "at         2,012\n",
      "one        2,028\n",
      "of         1,997\n",
      "russia     3,607\n",
      "'          1,005\n",
      "s          1,055\n",
      "largest    2,922\n",
      "public     2,270\n",
      "libraries   8,860\n",
      ",          1,010\n",
      "according   2,429\n",
      "to         2,000\n",
      "the        1,996\n",
      "russian    2,845\n",
      "state      2,110\n",
      "news       2,739\n",
      "agency     4,034\n",
      "ta        11,937\n",
      "##ss       4,757\n",
      ".          1,012\n",
      "the        1,996\n",
      "russian    2,845\n",
      "emergency   5,057\n",
      "situations   8,146\n",
      "ministry   3,757\n",
      "says       2,758\n",
      "147       16,471\n",
      "firefighters  21,767\n",
      "struggled   6,915\n",
      "for        2,005\n",
      "25         2,423\n",
      "hours      2,847\n",
      "over       2,058\n",
      "the        1,996\n",
      "weekend    5,353\n",
      "to         2,000\n",
      "put        2,404\n",
      "out        2,041\n",
      "the        1,996\n",
      "blaze     15,347\n",
      "in         1,999\n",
      "the        1,996\n",
      "main       2,364\n",
      "library    3,075\n",
      "of         1,997\n",
      "the        1,996\n",
      "institute   2,820\n",
      "for        2,005\n",
      "research   2,470\n",
      "information   2,592\n",
      "on         2,006\n",
      "social     2,591\n",
      "sciences   4,163\n",
      "in         1,999\n",
      "moscow     4,924\n",
      ".          1,012\n",
      "the        1,996\n",
      "fire       2,543\n",
      ",          1,010\n",
      "which      2,029\n",
      "ripped     9,157\n",
      "through    2,083\n",
      "the        1,996\n",
      "library    3,075\n",
      "friday     5,958\n",
      "evening    3,944\n",
      ",          1,010\n",
      "destroyed   3,908\n",
      "2          1,016\n",
      ",          1,010\n",
      "000        2,199\n",
      "square     2,675\n",
      "meters     5,563\n",
      "(          1,006\n",
      "about      2,055\n",
      "2          1,016\n",
      ",          1,010\n",
      "400        4,278\n",
      "square     2,675\n",
      "yards      4,210\n",
      ")          1,007\n",
      "of         1,997\n",
      "the        1,996\n",
      "building   2,311\n",
      "and        1,998\n",
      "caused     3,303\n",
      "part       2,112\n",
      "of         1,997\n",
      "the        1,996\n",
      "roof       4,412\n",
      "to         2,000\n",
      "collapse   7,859\n",
      ",          1,010\n",
      "according   2,429\n",
      "to         2,000\n",
      "an         2,019\n",
      "official   2,880\n",
      "statement   4,861\n",
      ".          1,012\n",
      "the        1,996\n",
      "russian    2,845\n",
      "emergency   5,057\n",
      "situations   8,146\n",
      "ministry   3,757\n",
      "said       2,056\n",
      "the        1,996\n",
      "fire       2,543\n",
      "was        2,001\n",
      "particularly   3,391\n",
      "hard       2,524\n",
      "to         2,000\n",
      "put        2,404\n",
      "out        2,041\n",
      "because    2,138\n",
      "of         1,997\n",
      "the        1,996\n",
      "high       2,152\n",
      "temperatures   7,715\n",
      ",          1,010\n",
      "narrow     4,867\n",
      "passageway  27,336\n",
      "##s        2,015\n",
      "and        1,998\n",
      "the        1,996\n",
      "risk       3,891\n",
      "of         1,997\n",
      "the        1,996\n",
      "building   2,311\n",
      "falling    4,634\n",
      "down       2,091\n",
      ".          1,012\n",
      "moscow     4,924\n",
      "'          1,005\n",
      "s          1,055\n",
      "emergency   5,057\n",
      "ministry   3,757\n",
      "said       2,056\n",
      "the        1,996\n",
      "temperature   4,860\n",
      "inside     2,503\n",
      "the        1,996\n",
      "rubble    17,538\n",
      "of         1,997\n",
      "the        1,996\n",
      "library    3,075\n",
      "remains    3,464\n",
      "high       2,152\n",
      "and        1,998\n",
      "that       2,008\n",
      "there      2,045\n",
      "is         2,003\n",
      "still      2,145\n",
      "a          1,037\n",
      "threat     5,081\n",
      "that       2,008\n",
      "the        1,996\n",
      "building   2,311\n",
      "could      2,071\n",
      "collapse   7,859\n",
      ".          1,012\n",
      "vladimir   8,748\n",
      "fort       3,481\n",
      "##ov       4,492\n",
      ",          1,010\n",
      "president   2,343\n",
      "of         1,997\n",
      "the        1,996\n",
      "russian    2,845\n",
      "academy    2,914\n",
      "of         1,997\n",
      "sciences   4,163\n",
      ",          1,010\n",
      "told       2,409\n",
      "the        1,996\n",
      "russian    2,845\n",
      "news       2,739\n",
      "agency     4,034\n",
      "ri        15,544\n",
      "##a        2,050\n",
      "novo      24,576\n",
      "##sti     16,643\n",
      "that       2,008\n",
      "the        1,996\n",
      "fire       2,543\n",
      ",          1,010\n",
      "which      2,029\n",
      "destroyed   3,908\n",
      "15         2,321\n",
      "%          1,003\n",
      "of         1,997\n",
      "all        2,035\n",
      "the        1,996\n",
      "documents   5,491\n",
      "in         1,999\n",
      "the        1,996\n",
      "library    3,075\n",
      ",          1,010\n",
      "reminded   6,966\n",
      "him        2,032\n",
      "of         1,997\n",
      "the        1,996\n",
      "1986       3,069\n",
      "disaster   7,071\n",
      "at         2,012\n",
      "the        1,996\n",
      "cher      24,188\n",
      "##nob     25,083\n",
      "##yl       8,516\n",
      "nuclear    4,517\n",
      "plant      3,269\n",
      "in         1,999\n",
      "ukraine    5,924\n",
      ".          1,012\n",
      "\"          1,000\n",
      "it         2,009\n",
      "'          1,005\n",
      "s          1,055\n",
      "a          1,037\n",
      "major      2,350\n",
      "loss       3,279\n",
      "for        2,005\n",
      "science    2,671\n",
      ".          1,012\n",
      "this       2,023\n",
      "is         2,003\n",
      "the        1,996\n",
      "largest    2,922\n",
      "collection   3,074\n",
      "of         1,997\n",
      "its        2,049\n",
      "kind       2,785\n",
      "in         1,999\n",
      "the        1,996\n",
      "world      2,088\n",
      ",          1,010\n",
      "probably   2,763\n",
      "equivalent   5,662\n",
      "to         2,000\n",
      "the        1,996\n",
      "library    3,075\n",
      "of         1,997\n",
      "congress   3,519\n",
      ",          1,010\n",
      "\"          1,000\n",
      "fort       3,481\n",
      "##ov       4,492\n",
      "told       2,409\n",
      "the        1,996\n",
      "agency     4,034\n",
      ".          1,012\n",
      "\"          1,000\n",
      "it         2,009\n",
      "contains   3,397\n",
      "material   3,430\n",
      "that       2,008\n",
      "you        2,017\n",
      "can        2,064\n",
      "'          1,005\n",
      "t          1,056\n",
      "find       2,424\n",
      "anywhere   5,973\n",
      "else       2,842\n",
      "and        1,998\n",
      "all        2,035\n",
      "the        1,996\n",
      "social     2,591\n",
      "science    2,671\n",
      "institutions   4,896\n",
      "use        2,224\n",
      "this       2,023\n",
      "library    3,075\n",
      ".          1,012\n",
      "what       2,054\n",
      "has        2,038\n",
      "happened   3,047\n",
      "here       2,182\n",
      "is         2,003\n",
      "reminiscent  14,563\n",
      "of         1,997\n",
      "cher      24,188\n",
      "##nob     25,083\n",
      "##yl       8,516\n",
      ".          1,012\n",
      "\"          1,000\n",
      "the        1,996\n",
      "institute   2,820\n",
      "'          1,005\n",
      "s          1,055\n",
      "director   2,472\n",
      ",          1,010\n",
      "yuri      14,331\n",
      "pi        14,255\n",
      "##vo       6,767\n",
      "##var     10,755\n",
      "##ov       4,492\n",
      ",          1,010\n",
      "told       2,409\n",
      "ta        11,937\n",
      "##ss       4,757\n",
      "that       2,008\n",
      "he         2,002\n",
      "fears     10,069\n",
      "the        1,996\n",
      "building   2,311\n",
      "cannot     3,685\n",
      "be         2,022\n",
      "restored   5,854\n",
      ".          1,012\n",
      "[SEP]        102\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "for token, id in zip(tokens, input_ids):\n",
    "    print('{:8}{:8,}'.format(token,id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n",
      "325\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#first occurence of [SEP] token\n",
    "sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "print(sep_idx)\n",
    "\n",
    "#number of tokens in segment A - question\n",
    "num_seg_a = sep_idx+1\n",
    "print(num_seg_a)\n",
    "\n",
    "#number of tokens in segment B - text\n",
    "num_seg_b = len(input_ids) - num_seg_a\n",
    "print(num_seg_b)\n",
    "\n",
    "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "print(segment_ids)\n",
    "\n",
    "assert len(segment_ids) == len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token input_ids to represent the input\n",
    "#token segment_ids to differentiate our segments - text and question \n",
    "output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "#print(output.start_logits, output.end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens with highest start and end scores\n",
    "answer_start = torch.argmax(output.start_logits)\n",
    "answer_end = torch.argmax(output.end_logits)\n",
    "#print(answer_start, answer_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "Moscow (cnn)more than 1 million historic documents have been destroyed in a fire at one of russia's largest public libraries, according to the russian state news agency tass. \n",
      "\n",
      "the russian emergency situations ministry says 147 firefighters struggled for 25 hours over the weekend to put out the blaze in the main library of the institute for research information on social sciences in moscow. \n",
      "\n",
      "the fire, which ripped through the library friday evening, destroyed 2,000 square meters (about 2,400 square yards) of the building and caused part of the roof to collapse, according to an official statement. the russian emergency situations ministry said the fire was particularly hard to put out because of the high temperatures, narrow passageways and the risk of the building falling down. \n",
      "\n",
      "moscow's emergency ministry said the temperature inside the rubble of the library remains high and that there is still a threat that the building could collapse. \n",
      "\n",
      "vladimir fortov, president of the russian academy of sciences, told the russian news agency ria novosti that the fire, which destroyed 15% of all the documents in the library, reminded him of the 1986 disaster at the chernobyl nuclear plant in ukraine. \n",
      "\n",
      "\"it's a major loss for science. this is the largest collection of its kind in the world, probably equivalent to the library of congress,\" fortov told the agency. \"it contains material that you can't find anywhere else and all the social science institutions use this library. what has happened here is reminiscent of chernobyl.\" \n",
      "\n",
      "the institute's director, yuri pivovarov, told tass that he fears the building cannot be restored. \n",
      "\n",
      "Question:\n",
      "When did that happen?\n",
      "\n",
      "Answer:\n",
      "Friday evening.\n"
     ]
    }
   ],
   "source": [
    "if answer_end >= answer_start:\n",
    "    answer = \" \".join(tokens[answer_start:answer_end+1])\n",
    "else:\n",
    "    print(\"I am unable to find the answer to this question. Can you please ask another question?\")\n",
    "    \n",
    "print(\"Text:\\n{}\".format(text.capitalize()))\n",
    "print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
    "print(\"\\nAnswer:\\n{}.\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_scores = output.start_logits.detach().numpy().flatten()\n",
    "end_scores = output.end_logits.detach().numpy().flatten()\n",
    "\n",
    "token_labels = []\n",
    "for i, token in enumerate(tokens):\n",
    "    token_labels.append(\"{}-{}\".format(token,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(token_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #first 100 tokens\n",
    "# plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "# ax = sns.barplot(x=token_labels[:80], y=start_scores[:80], ci=None)\n",
    "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "# ax.grid(True)\n",
    "# plt.title(\"Start word scores\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #last 100 tokens\n",
    "# plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "# ax = sns.barplot(x=token_labels[-80:], y=start_scores[-80:], ci=None)\n",
    "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "# ax.grid(True)\n",
    "# plt.title(\"Start word scores\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #first 100 tokens\n",
    "# plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "# ax = sns.barplot(x=token_labels[:80], y=end_scores[:80], ci=None)\n",
    "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "# ax.grid(True)\n",
    "# plt.title(\"End word scores\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #last 100 tokens\n",
    "# plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "# ax = sns.barplot(x=token_labels[-80:], y=end_scores[-80:], ci=None)\n",
    "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "# ax.grid(True)\n",
    "# plt.title(\"End word scores\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to join the broken words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = tokens[answer_start]\n",
    "\n",
    "for i in range(answer_start+1, answer_end+1):\n",
    "    if tokens[i][0:2] == \"##\":\n",
    "        answer += tokens[i][2:]\n",
    "    else:\n",
    "        answer += \" \" + tokens[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer(question, text):\n",
    "    \n",
    "    #tokenize question and text in ids as a pair\n",
    "    input_ids = tokenizer.encode(question, text)\n",
    "    \n",
    "    #string version of tokenized ids\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    \n",
    "    #segment IDs\n",
    "    #first occurence of [SEP] token\n",
    "    sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    #number of tokens in segment A - question\n",
    "    num_seg_a = sep_idx+1\n",
    "\n",
    "    #number of tokens in segment B - text\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "    \n",
    "    #list of 0s and 1s\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "    \n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "    \n",
    "    #model output using input_ids and segment_ids\n",
    "    output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "    \n",
    "    #reconstructing the answer\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "\n",
    "    if answer_end >= answer_start:\n",
    "        answer = tokens[answer_start]\n",
    "        for i in range(answer_start+1, answer_end+1):\n",
    "            if tokens[i][0:2] == \"##\":\n",
    "                answer += tokens[i][2:]\n",
    "            else:\n",
    "                answer += \" \" + tokens[i]\n",
    "                \n",
    "    if answer.startswith(\"[CLS]\"):\n",
    "        answer = \"Unable to find the answer to your question.\"\n",
    "    \n",
    "#     print(\"Text:\\n{}\".format(text.capitalize()))\n",
    "#     print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
    "    print(\"\\nAnswer:\\n{}\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"\"\"New York (CNN) -- More than 80 Michael Jackson collectibles -- including the late pop star's famous rhinestone-studded glove from a 1983 performance -- were auctioned off Saturday, reaping a total $2 million. Profits from the auction at the Hard Rock Cafe in New York's Times Square crushed pre-sale expectations of only $120,000 in sales. The highly prized memorabilia, which included items spanning the many stages of Jackson's career, came from more than 30 fans, associates and family members, who contacted Julien's Auctions to sell their gifts and mementos of the singer. Jackson's flashy glove was the big-ticket item of the night, fetching $420,000 from a buyer in Hong Kong, China. Jackson wore the glove at a 1983 performance during \\\"Motown 25,\\\" an NBC special where he debuted his revolutionary moonwalk. Fellow Motown star Walter \\\"Clyde\\\" Orange of the Commodores, who also performed in the special 26 years ago, said he asked for Jackson's autograph at the time, but Jackson gave him the glove instead. \"The legacy that [Jackson] left behind is bigger than life for me,\\\" Orange said. \\\"I hope that through that glove people can see what he was trying to say in his music and what he said in his music.\\\" Orange said he plans to give a portion of the proceeds to charity. Hoffman Ma, who bought the glove on behalf of Ponte 16 Resort in Macau, paid a 25 percent buyer's premium, which was tacked onto all final sales over $50,000. Winners of items less than $50,000 paid a 20 percent premium.\"\"\"\n",
    "# question = \"Where was the Auction held?\"\n",
    "\n",
    "# question_answer(question, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Original answer:\\n\", data.loc[data[\"question\"] == question][\"answer\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing with the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = input(\"Please enter your text: \\n\")\n",
    "# question = input(\"\\nPlease enter your question: \\n\")\n",
    "\n",
    "# while True:\n",
    "#     question_answer(question, text)\n",
    "#     question = input(\"\\nPlease enter your question: \\n\")\n",
    "\n",
    "    \n",
    "    # flag = True\n",
    "    # flag_N = False\n",
    "    \n",
    "    # while flag:\n",
    "    #     response = input(\"\\nDo you want to ask another question based on this text (Y/N)? \")\n",
    "        # if response[0] == \"Y\":\n",
    "            # flag = False\n",
    "    #     elif response[0] == \"N\":\n",
    "    #         print(\"\\nBye!\")\n",
    "    #         flag = False\n",
    "    #         flag_N = True\n",
    "            \n",
    "    # if flag_N == True:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serilization Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained('Chatbot_model_directory')\n",
    "model.save_pretrained('Chatbot_model_directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
